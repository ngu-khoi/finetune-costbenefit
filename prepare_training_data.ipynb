{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare_training_data\n",
    "**Author:** Khoi Nguyen\n",
    "\n",
    "**Date created:** 03/06/2023\n",
    "\n",
    "**Last modified:** 04/15/2023\n",
    "\n",
    "**Description:** This notebook is used to create the response-completion pairs for training the `Ada` models. This task is accomplished by using the `test` sets w/ the \"Improve this sentence:\" prompt and submitting that to `Curie` to create synthetic datasets.\n",
    "\n",
    "**WARNING:** This notebook requires API calls and will cost money. Please be careful when running this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "instruction = \"Elaborate on the following sentence: \""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k_ada\n",
    "Synthesizing `1k_ada` training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmation = input('Are you sure you want to run 1k_ada synthethic training creation? Type YES or NO: ')\n",
    "\n",
    "if confirmation == 'YES':\n",
    "    with open('data/1k_ada/train.json') as f:\n",
    "        train_data = json.load(f)\n",
    "\n",
    "    with open('data/1k_ada/openai_training.jsonl', 'w') as outfile:\n",
    "        for sentence in tqdm.tqdm(train_data):\n",
    "            prompt = \"{instruction}\\\"{sentence}\\\"\\n\\n\".format(sentence=sentence[\"sentence\"], instruction=instruction)\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-curie-001\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.7,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            outfile.write(json.dumps({\n",
    "                'prompt': prompt,\n",
    "                'completion': response.choices[0].text\n",
    "            }) + '\\n')\n",
    "            outfile.flush()\n",
    "else:\n",
    "    print('Synthethic training creation aborted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in openai_training.jsonl and print the first 10 lines\n",
    "with open('data/1k_ada/openai_training.jsonl') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n. The separator should not appear elsewhere in any prompt.\n",
    "# Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "# Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "# For inference, you should format your prompts in the same way as you did when creating the training dataset, including the same separator. Also specify the same stop sequence to properly truncate the completion.\n",
    "\n",
    "with open('data/1k_ada/openai_training.jsonl', 'r') as f:\n",
    "    with open('data/1k_ada/openai_cleaned.jsonl', 'w') as out:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            prompt = data['prompt'].strip() + '\\n\\n##\\n\\n'\n",
    "            completion = ' ' + data['completion'].strip() + '\\n'\n",
    "            out.write(json.dumps({'prompt': prompt, 'completion': completion}))\n",
    "            out.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in openai_cleaned.jsonl and print the first 5 lines with prettier formatting\n",
    "with open('data/1k_ada/openai_cleaned.jsonl') as f:\n",
    "    for i in range(5):\n",
    "        print(json.dumps(json.loads(f.readline()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command in the terminal to use the OpenAI CLI Data Preparation Tool to prepare the data for training.\n",
    "# In addition to the cleaning processes above, the tool will remove the prompt instruction\n",
    "# ! openai tools fine_tunes.prepare_data -f data/1k_ada/openai_cleaned.jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k_ada\n",
    "Synthesizing `10k_ada` training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:41:43<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "confirmation = input('Are you sure you want to run 10k_ada synthethic training creation? Type YES or NO: ')\n",
    "\n",
    "if confirmation == 'YES':\n",
    "    with open('data/10k_ada/train.json') as f:\n",
    "        train_data = json.load(f)\n",
    "\n",
    "    with open('data/10k_ada/openai_training.jsonl', 'w') as outfile:\n",
    "        for sentence in tqdm.tqdm(train_data):\n",
    "            prompt = \"{instruction}\\\"{sentence}\\\"\\n\\n\".format(sentence=sentence[\"sentence\"], instruction=instruction)\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-curie-001\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.7,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            outfile.write(json.dumps({\n",
    "                'prompt': prompt,\n",
    "                'completion': response.choices[0].text\n",
    "            }) + '\\n')\n",
    "            outfile.flush()\n",
    "else:\n",
    "    print('Synthethic training creation aborted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"prompt\": \"Elaborate on the following sentence: \\\"All jet engines have a combustor or burner in which the air and fuel are mixed and burned.\\\"\\n\\n\", \"completion\": \"\\n\\nJet engines typically have a combustor or burner in which the air and fuel are mixed and burned. This mixture is then forced into the engine's exhaust pipe where it is burned to create thrust.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Melanin is what darkens the skin, producing a suntan.\\\"\\n\\n\", \"completion\": \"\\n\\nMelanin is a pigment found in the skin that produces a tan.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Nutritious snacks are smart ways to get the nutrients and energy needed to work, play and grow.\\\"\\n\\n\", \"completion\": \"\\n\\nA nutritious snack can be anything that provides nutrients and energy, such as a piece of fruit, a yogurt, a granola bar, or a piece of dark chocolate. Snacks can be a great way to get the nutrients and energy you need to function optimally. They can also help you to stay alert and focused during the day, which can help you to grow and learn.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Flies prefer to stick with dirty areas such as fecal matter or garbage bins for egg laying.\\\"\\n\\n\", \"completion\": \"\\n\\nThis sentence is saying that flies prefer to lay their eggs in areas that are dirty. This could mean that the flies are attracted to the smell of fecal matter or garbage bins.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Experiments include plants.\\\"\\n\\n\", \"completion\": \"\\n\\n\\\"Experiments include plant growth, animal behavior, and chemical reactions.\\\"\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Object pronouns precede the verb and are divided into direct and indirect objects.\\\"\\n\\n\", \"completion\": \"\\n\\nDirect objects are the people or things that the verb is directly addressed to. Indirect objects are the people or things that the verb is indirectly addressed to.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Raccoons also consume clapper rail eggs and young.\\\"\\n\\n\", \"completion\": \"\\n\\nThe sentence states that raccoons also consume clapper rail eggs and young. This means that the raccoons are eating the eggs and young of the clapper rail.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Personal information is information that can be used to locate an individual online or offline.\\\"\\n\\n\", \"completion\": \"\\n\\nThis sentence is referring to personal information that can be used to contact or locate an individual. This could be their name, address, email address, or phone number.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Subordinate animals become undernourished because of food competition.\\\"\\n\\n\", \"completion\": \"\\n\\nOne way that subordinate animals become undernourished is because they are competing with other animals for food. This can happen because the subordinate animal is smaller or weaker than the other animals, or because it cannot find enough food to survive.\"}\n",
      "\n",
      "{\"prompt\": \"Elaborate on the following sentence: \\\"Innate intelligence is the essence of life itself.\\\"\\n\\n\", \"completion\": \"\\n\\nInnate intelligence is the essence of life itself. This means that without it, life would not be possible. Innate intelligence is what allows us to think, reason, and make decisions. It is what allows us to experience life and grow.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load in openai_training.jsonl and print the first 10 lines\n",
    "with open('data/10k_ada/openai_training.jsonl') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n. The separator should not appear elsewhere in any prompt.\n",
    "# Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "# Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "# For inference, you should format your prompts in the same way as you did when creating the training dataset, including the same separator. Also specify the same stop sequence to properly truncate the completion.\n",
    "\n",
    "with open('data/10k_ada/openai_training.jsonl', 'r') as f:\n",
    "    with open('data/10k_ada/openai_cleaned.jsonl', 'w') as out:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            prompt = data['prompt'].strip() + '\\n\\n##\\n\\n'\n",
    "            completion = ' ' + data['completion'].strip() + '\\n'\n",
    "            out.write(json.dumps({'prompt': prompt, 'completion': completion}))\n",
    "            out.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command in the terminal to use the OpenAI CLI Data Preparation Tool to prepare the data for training.\n",
    "# In addition to the cleaning processes above, the tool will remove the prompt instruction\n",
    "# ! openai tools fine_tunes.prepare_data -f data/10k_ada/openai_cleaned.jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k_ada\n",
    "Synthesizing `100k_ada` training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmation = input('Are you sure you want to run 100k_ada synthethic training creation? Type YES or NO: ')\n",
    "\n",
    "if confirmation == 'YES':\n",
    "    with open('data/100k_ada/train.json') as f:\n",
    "        train_data = json.load(f)\n",
    "\n",
    "    with open('data/100k_ada/openai_training.jsonl', 'w') as outfile:\n",
    "        for sentence in tqdm.tqdm(train_data):\n",
    "            prompt = \"{instruction}\\\"{sentence}\\\"\\n\\n\".format(sentence=sentence[\"sentence\"], instruction=instruction)\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-curie-001\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.7,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            outfile.write(json.dumps({\n",
    "                'prompt': prompt,\n",
    "                'completion': response.choices[0].text\n",
    "            }) + '\\n')\n",
    "            outfile.flush()\n",
    "else:\n",
    "    print('Synthethic training creation aborted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in openai_training.jsonl and print the first 10 lines\n",
    "with open('data/100k_ada/openai_training.jsonl') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n. The separator should not appear elsewhere in any prompt.\n",
    "# Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "# Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "# For inference, you should format your prompts in the same way as you did when creating the training dataset, including the same separator. Also specify the same stop sequence to properly truncate the completion.\n",
    "\n",
    "with open('data/100k_ada/openai_training.jsonl', 'r') as f:\n",
    "    with open('data/100k_ada/openai_cleaned.jsonl', 'w') as out:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            prompt = data['prompt'].strip() + '\\n\\n##\\n\\n'\n",
    "            completion = ' ' + data['completion'].strip() + '\\n'\n",
    "            out.write(json.dumps({'prompt': prompt, 'completion': completion}))\n",
    "            out.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command in the terminal to use the OpenAI CLI Data Preparation Tool to prepare the data for training.\n",
    "# In addition to the cleaning processes above, the tool will remove the prompt instruction\n",
    "# ! openai tools fine_tunes.prepare_data -f data/100k_ada/openai_cleaned.jsonl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
